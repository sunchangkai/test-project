{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Data Management User Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we use Traffic Sign Recognition(TSR) dataset as an example to demo how to import the metadata of the dataset into ProSafeAI Evaluation Tool which can be further used for [Data distribution](2.2.data_distribution.ipynb) & [Data Verification](2.3.data_verification.ipynb) in Data V and [basic metrics](3.1.basic_metrics.ipynb) & [Robustness test](3.2.robustness_test.ipynb) in Model V."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.Prerequisites\n",
    "\n",
    "* You need a Python environment to run this code.\n",
    "\n",
    "* You need to align with ProSafeAI CN team(contacts are listed as below) to create the schema of your metadata of your dataset.\n",
    "  - Xia, Xi (C|TN-12) <xi.xia@cariad-technology.cn> \n",
    "  - Yi, Wukun (C|TN-12) <Wukun.Yi@cariad-technology.cn> \n",
    "\n",
    "* You need to prepare a Python or other language script to convert the original metadata into the format as the exported from ProSafeAI Evaluation Tool after aligning with ProSafeAI CN team and creating the schema after the alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.Prepare metadata\n",
    "\n",
    "This script converts the original metadata of the dataset into the format as the template exported from ProSafeAI Evaluation Tool after aligning with ProSafeAI CN team and creating the schema after the alignment.\n",
    "\n",
    "### 2.1.ETL script for Traffic Sign Recognition(TSR)\n",
    "For example, in the user case of Traffic Sign Recognition(TSR), we will use the following script to convert te original metadata into required format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data: ./data/label_train.txt\n",
      "format_data:  ./data/TSR_format_metadata.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "original metadata: ./data/TSR_data/label_train.txt\n",
    "the expected format of the metadata looks like the following json:\n",
    "[\n",
    "    {\n",
    "            \"image_name\": \"\",\n",
    "            \"image_format\": \"\",\n",
    "            \"class\": \"\",\n",
    "            \"Snowfall_intensity\": \"\",\n",
    "            \"Fog_intensity\": \"\",\n",
    "            \"Rain_quantity\": \"\",\n",
    "            \"dataset\": \"\",\n",
    "            \"augmentation\": \"\",\n",
    "            \"Illuminance\": \"\"       \n",
    "    }\n",
    "]\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "\n",
    "def scan_data(data_path, format_data_path):\n",
    "\n",
    "    print(\"input data:\", data_path)\n",
    "\n",
    "    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = [line.strip().split(\"\\t\") for line in f.readlines()]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for pic_name, value in data:\n",
    "        sub_dict = json.loads(value)\n",
    "\n",
    "        info = {\n",
    "            \"image_name\": pic_name,\n",
    "            \"image_format\": pic_name.split(\".\")[1],\n",
    "            \"class\": sub_dict.get(\"class\"),\n",
    "            \"Snowfall_intensity\": sub_dict.get(\"Snowfall_intensity\"),\n",
    "            \"Fog_intensity\": sub_dict.get(\"Fog_intensity\"),\n",
    "            \"Rain_quantity\": sub_dict.get(\"Rain_quantity\"),\n",
    "            \"dataset\": sub_dict.get(\"dataset\"),\n",
    "            \"augmentation\": sub_dict.get(\"augmentation\"),\n",
    "            \"Illuminance\": sub_dict.get(\"Illuminance\"),\n",
    "        }\n",
    "\n",
    "        results.append(info)\n",
    "\n",
    "    with open(os.path.join(format_data_path, \"TSR_format_metadata.json\"), \"w\", encoding=\"utf-8\") as fw:\n",
    "        json.dump(results, fw)\n",
    "\n",
    "    print('format_data: ', os.path.join(format_data_path, \"TSR_format_metadata.json\"))\n",
    "\n",
    "scan_data(\"./data/TSR_data/label_train.txt\", \"./data/TSR_data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2.ETL script for Pedestrian and Vehicle Detection(PVD)\n",
    "\n",
    "For example, in the user case of Pedestrian and Vehicle Detection(PVD), we will use the following script to convert the original metadata into required format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "original data: ./data/bdd100k\n",
    "the expected format of the metadata looks like the following json:\n",
    "[\n",
    "    {\n",
    "        \"image_path\": \"\",\n",
    "        \"image_name\": \"\",\n",
    "        \"image_size\": {\n",
    "            \"height\": 720,\n",
    "            \"width\": 1280,\n",
    "         },\n",
    "        \"weather\": \"\",\n",
    "        \"scene\": \"\",\n",
    "        \"timeofday\": \"\",\n",
    "        \"objects\": [\n",
    "            {\n",
    "                \"object_class\": 0,\n",
    "                \"tag\": {\n",
    "                    \"bbox\": [\n",
    "                        450.643725,\n",
    "                        261.277479,\n",
    "                        491.393423,\n",
    "                        328.39463,\n",
    "                    ],\n",
    "                },\n",
    "                \"object_code\": 0,\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "\n",
    "def scan_data(data_path):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    category2id = {\n",
    "        \"car\": 0,\n",
    "        \"bus\": 1,\n",
    "        \"person\": 2,\n",
    "        \"bike\": 3,\n",
    "        \"truck\": 4,\n",
    "        \"motor\": 5,\n",
    "        \"train\": 6,\n",
    "        \"rider\": 7,\n",
    "    }\n",
    "\n",
    "    for root, dirs, files in os.walk(data_path + \"labels\"):\n",
    "        for file_name in files:\n",
    "            tmp = dict()\n",
    "\n",
    "            file_path = os.path.join(root, file_name)\n",
    "\n",
    "            with open(file_path, encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            img_name = file_name.replace(\"json\", \"jpg\")\n",
    "\n",
    "            img = cv2.imread(os.path.join(data_path + \"images\", img_name))\n",
    "\n",
    "            height, width = img.shape[0:2]\n",
    "\n",
    "            tmp[\"image_path\"] = os.path.join(\"/data/bdd100k/images\", img_name)\n",
    "            tmp[\"image_name\"] = img_name\n",
    "            tmp[\"image_size\"] = {\"height\": height, \"width\": width}\n",
    "\n",
    "            tmp[\"weather\"] = data[\"attributes\"][\"weather\"]\n",
    "            tmp[\"scene\"] = data[\"attributes\"][\"scene\"]\n",
    "            tmp[\"timeofday\"] = data[\"attributes\"][\"timeofday\"]\n",
    "\n",
    "            for sub in data[\"frames\"][0][\"objects\"]:\n",
    "                if sub[\"category\"] in category2id:\n",
    "                    tmp.setdefault(\"objects\", []).append(\n",
    "                        {\n",
    "                            \"object_class\": category2id[sub[\"category\"]],\n",
    "                            \"tag\": {\n",
    "                                \"bbox\": [\n",
    "                                    sub[\"box2d\"][\"x1\"],\n",
    "                                    sub[\"box2d\"][\"y1\"],\n",
    "                                    sub[\"box2d\"][\"x2\"],\n",
    "                                    sub[\"box2d\"][\"y2\"],\n",
    "                                ],\n",
    "                                \"occluded\": sub[\"attributes\"][\"occluded\"],\n",
    "                                \"truncated\": sub[\"attributes\"][\"truncated\"],\n",
    "                                \"trafficLightColor\": sub[\"attributes\"][\n",
    "                                    \"trafficLightColor\"\n",
    "                                ],\n",
    "                            },\n",
    "                            \"object_code\": category2id[sub[\"category\"]],\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "            results.append(tmp)\n",
    "\n",
    "    with open(\"./data/bdd100k/bdd100k_mini.json\", \"w\", encoding=\"utf-8\") as fw:\n",
    "        json.dump(results, fw, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "scan_data(data_path=\"./data/bdd100k/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run the script above, you will generate the formatted metadata JSON file `/data/bdd100k/bdd100k_mini.json` in your local disk."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.Import data\n",
    "After converting the original metadata as the template, we can use the generated JSON file(TSR_format_metadata.json for TSR) to import ProsafeAI Evaluation Tool.\n",
    "\n",
    "Open [http://10.38.49.30:8080/](http://10.38.49.30:8080/), then input your username, password and verification code.\n",
    "After the successful login, click on <span style=\"color:red;font-weight:bold\">Data Management</span> in the left menu or Quick navigation.\n",
    "\n",
    "\n",
    "![table list](./media/table_list.png)\n",
    "\n",
    "We obtain a table list containing some attributes such as project name, user case, table name, description, field summary, task type, the latest version, etc. This list only displays the data that your account has permission to access. When your mouse hovers over the field summary, the column names of this table are displayed. These columns are aligned with ProSafeAI CN team, and the schema is created after alignment. If you can't find your dataset's schema, please contact ProSafeAI CN Team as soon as possible.\n",
    "\n",
    "We select the row for TSR and click the `view details` button to enter the details page.\n",
    "\n",
    "![table detail](./media/table_detail.png)\n",
    "\n",
    "This page shows metadata in detail. We can click `View Other Version`, then choose a version and click `commit`, the page will display the selected data version.\n",
    "\n",
    "We click `import New Data` to import new data.\n",
    "\n",
    "![iport data](./media/import_data.png)\n",
    "\n",
    "First, we need click `preview and download json template`, then we can download a template which is generated based on the schema pre-aligned with ProSafeAI CN team. For example, here is the JSON template for a specific dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% json\n"
    }
   },
   "outputs": [],
   "source": [
    "[\n",
    "    {\n",
    "        \"image_name\": \"string\",\n",
    "        \"image_format\": \"string\",\n",
    "        \"augmentation\": \"string\",\n",
    "        \"dataset\": \"string\",\n",
    "        \"class\": \"string\",\n",
    "        \"Fog_intensity\": \"string\",\n",
    "        \"Snowfall_intensity\": \"string\",\n",
    "        \"Illuminance\": \"string\",\n",
    "        \"Rain_quantity\": \"string\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We need to check if the prepared metadata(for example, `TSR_format_metadata.json` which is generated in the first step in this tutorial) meets the format as the exported template from ProSafeAI Evaluation Tool. If not, we need to modify the Python or other language script and re-generate the metadata until its format is correct. If it meets the format requirement, we can check the box `I have previewd and downloaded the template`, at the same time, the `Browse` button is available.\n",
    "\n",
    "\n",
    "Second, we can click `Browse` button and upload the prepared metadata JSON file(e.g. `TSR_format_metadata.json`). Then, we input a table version description in `version comments` to distinguish the differences between different versions. Finally, we click the `commit` button to commit this data version.\n",
    "\n",
    "We can see the latest uploaded data on the page and filter the data through the filtering box above.\n",
    "\n",
    "Until now, you should have successfully imported your metadata of your dataset into ProSafeAI Evaluation Tool, and this metadata inforamtion is important for the following tasks such us [Data distribution](2.2.data_distribution.ipynb), [Data Verification](2.3.data_verification.ipynb) in `Data V` & [Basic Metrics](3.1.basic_metrics.ipynb) & [Robustness Test](3.2.robustness_test.ipynb) in `Model V`.\n",
    "\n",
    "Now, you can jump to [Data distribution](2.2.data_distribution.ipynb) to see how your data distribution looks like for your dataset,enjoy^_^."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
