{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. What is ProSafeAI Evaluation Tool\n",
    "\n",
    "According to CPM 03.12 Engineer AI(China Verrsion), we seperated the AI engineering process as 3 V models: `Data V`, `Model V` & `Porting V`. And `ProSafeAI Evaluation Tool` is a platform to do AI data verification & model evaluation to test the non-functional metrics such us dataset coverage, basic performance (accuracy, precision, recall, F1-score), robustness, uncertainty, interpretability & diagnosis of AI models.\n",
    "\n",
    "Main features:\n",
    "* DataV:\n",
    "    * [Data management](2.1.data_management.ipynb)\n",
    "    * [Data Distribution](2.2.data_distribution.ipynb)\n",
    "    * [Data Verification](2.3.data_verification.ipynb) \n",
    "* ModelV:\n",
    "    * [Basic Metrics](3.1.basic_metrics.ipynb) (Image Classfication, Object Detection)  \n",
    "    * [Robustness Test](3.2.robustness_test.ipynb) (Image Classfication, Object Detection)  \n",
    "* Porting V:\n",
    "    * [Drift Detection](4.1.drift_detection.ipynb) (coming soon)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. How to get your account(username/passwword) to ProSafeAI Evaluation Tool\n",
    "If you don't have account to ProSafeAI Evaluation Tool yet, please kindly send email to Xia, Xi (C|TN-12) <xi.xia@cariad-technology.cn> & Yi, Wukun (C|TN-12) <Wukun.Yi@cariad-technology.cn> to create your account. \n",
    "\n",
    "# 3. Quick Start\n",
    "\n",
    "First, Login to ProSafeAI platform, and open [http://10.38.49.30:8080/](http://10.38.49.30:8080/). Then input your username, password and verification code.\n",
    "\n",
    "![login_page](./media/login.png)\n",
    "\n",
    "\n",
    "And then, we enter the workbench page.\n",
    "\n",
    "![workbench](./media/workbench.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Introduction for this tutorial\n",
    "In this tutorial, we will use 2 user cases to guide you how to use our ProSafeAI Evaluation Tool step by step. The first user case is image classfication task, and the second user case is object detection task. For the image classification task, we will use Traffic Sign Recognition(TSR) as example. For the object detection task, we will use Pedestrian and Vehicle Detection(PVD) as example. As well, the evaluation metrics would be introduced. For image classification task, we will use accuracy, precision, recall, F1-score as evaluation metrics. For object detection task, we will use mAP, precision, recall, F1-score as evaluation metrics. The details would be illustrated in the corresponding user case.\n",
    "\n",
    "## 4.1 User Case 1(image classfication): Traffic Sign Recognition(TSR)\n",
    "Traffic Sign Recognition(TSR) is an image classification task to judge if an image with traffic sign belongs to which class(speed limitation, construction sign etc.)\n",
    "* `Dataset`: Traffic sign images cropped from A2D2 dataset, and it contains 7 classes which are:\n",
    "    * 0: Background\n",
    "    * 1: Construction Sign\n",
    "    * 2: Speed Limit 60\n",
    "    * 3: Speed Limit 70\n",
    "    * 4: Speed Limit 80\n",
    "    * 5: Speed Limit 100\n",
    "    * 6: Speed Limit 120\n",
    "- `Data Distribution`: We split the dataset into 2 parts randomly: 40000 images for training and 30000 images for testing. The distribution of dataset would be shown as below:\n",
    "    * ###insert the distribution of each class\n",
    "- `Model`: We use ResNet18 as our model, and the model is trained by Pytorch.\n",
    "- `Evaluation Metrics`: Accuracy, Precision, Recall, F1-score would be as applied.\n",
    "\n",
    "## 4.2 User Case 2(object detection): Pedestrian and Vehicle Detection(PVD).\n",
    "Pedestrian and Vehicle Detection(PVD) is a object detection task whic is using deep learning to detect the pedestrian & vehicle from the images captured from the cameras of the vehicle.\n",
    "* `Dataset`: BDD100K(https://github.com/bdd100k/bdd100k) is the largest open driving video dataset with 100K videos and 10 tasks to evaluate the exciting progress of image recognition algorithms on autonomous driving. It could support the following 10 tasks:\n",
    "    * Image tagging\n",
    "    * Object detection\n",
    "    * Lane detection\n",
    "    * Instance segmentation\n",
    "    * Drivable area segmentation\n",
    "    * Domain adaptation\n",
    "    * Semantic segmentation\n",
    "    * Multi-object tracking\n",
    "    * Panoptic segmentation\n",
    "    * Video object segmentation\n",
    "- `Data Distribution`: In our case, we choose the object detection task to detect the pedestrian & vehicle from the images captured from the cameras of the vehicle. 70000 images would be selected from BDD100K dataset to train the model, and 10000 images would be selected from BDD100K dataset to validate the model.\n",
    "    - ###insert the distribution of each class\n",
    "* `Model`: The SOTA algorithm YOLOv5 would be used to train the model, and the model is trained by Pytorch.\n",
    "* `Evaluation Metrics`: mAP, Precision, Recall would be as applied.\n",
    "\n",
    "Let's begin from the first step: [Data management](2.1.data_management.ipynb) , enjoy^_^."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, May  7 2023, 23:32:44) \n[Clang 14.0.3 (clang-1403.0.22.14.1)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
