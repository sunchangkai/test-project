{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Data Verification User Guide\n",
    "\n",
    "In this tutorial, we will guide you how to do the data verification step by step based on Traffic Sign Recognition(TSR) and Pedestrian and Vehicle Detection(PVD) user cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Prerequisites\n",
    "* You have already imported the metadata of of your dataset accoding to the guiance of [Data management](2.1.data_management.ipynb).\n",
    "* You have already defined the `data requirments` in `ArhiE` software and exported as `data_requirement.json`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Testing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Create Task\n",
    "From the left menu, click DataV -> `Data Verification` link, you will find the `+ New Task` button, click it and you will find the form as below:\n",
    "![Data Verfication Create Task](./media/data_verification_createtask.png)\n",
    "\n",
    "* `Task Name`: task name\n",
    "* `Dataset to be tested` : it can be determinted by `choose a table` & `choose a table version`.\n",
    "* `Data requirement`: it can be determinted by `Choose a requirement`. Normally, a `data requirement` should be defined in `ArchE`(a PMT tool) based on dataset requirement and exported as a json file. And `data requirement` defines the requiremnts on accuracy, representativeness, consistency of the dataset for the AI model and user case. And each rule of the `Data requirement` will be a test case. Here is the sample of the `data_requirement.json` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "original metadata: ./data/TSR_data/data_requirement.json\n",
    "# @Xia Xi, would you please help to add the data_requirement.json here?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also preview how the test cases in the `data_requirement.json` looks like after it's uploaded, for example:\n",
    "![Data Verification](./media/data_verification_datarequirement.png)\n",
    "\n",
    "For each of the rule, it has 5 parameters:\n",
    "\n",
    "| Field Name | Field description | example |\n",
    "| :-----: | :----: | :----: |\n",
    "| Rule Name | rule id defined in `ArhiE` | data-bdd-21 |\n",
    "| Classification | rule type |  accuracy, representativeness or consistency |\n",
    "| Verification Object | the object or tested | datasetï¼Œclass label|\n",
    "| Verification Content |the metrics of the object to be tested | parameter coverage, label balance, scenario coverage etc.|\n",
    "| Computiation Rule | a json with the computation rule how to check if a rule is satified | { \"metric\": \"count\", \"operator\": \">=\", \"threshold\": 5, \"scenario\": [ { \"odd_parameter\": \"weather\", \"odd_class\": \"snowy\" }, { \"odd_parameter\": \"scene\", \"odd_class\": \"parking lot\" } ] } |\n",
    "\n",
    "Please refer to the `data requirement` documents for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Check testing result online\n",
    "Click on `View Sub-task`, you can find the testing result as the screenshot below:\n",
    "\n",
    "![data_verification_result](media/data_verification_result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Download the testing report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on `generate report and download`, you can download a PDF report, when open it, it looks like below:\n",
    "\n",
    "![data_verification_result_pdf](media/data_verification_report_pdf.png)\n",
    "\n",
    "Until Now, you can go through all the steps about how to do data verification and generate the testing report. If you wants to know more about the testing report, please contact ProSafeAI CN team."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
